import time, random, csv
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

SEARCH_KEYWORD = "ì‹¤ë‚´ ë””ìì¸"
START_PAGE = 11
END_PAGE = 30
OUT_FILE = f"riss_metadata_{START_PAGE}_{END_PAGE}.csv"

START_URL = (
    "https://www.riss.kr/search/Search.do?"
    f"query={SEARCH_KEYWORD}&pageNumber={START_PAGE}&iStartCount={(START_PAGE-1)*10}&pageScale=10&isTab=Y&"
    "icate=re_a_kor&colName=re_a_kor"
)

MIN_DELAY, MAX_DELAY = 3.0, 6.0

options = webdriver.ChromeOptions()
options.add_argument("--start-maximized")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(driver, 12)

def human_delay():
    time.sleep(random.uniform(MIN_DELAY, MAX_DELAY))

def extract_detail_fields():
    try:
        detail = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, ".infoDetailL")))
    except:
        return {"authors": "", "publisher": "", "journal": "", "issue": "", "year": ""}

    def get_field(field_name):
        try:
            el = detail.find_element(By.XPATH, f".//span[text()='{field_name}']/following-sibling::div//p")
            return el.text.strip()
        except:
            return ""

    return {
        "authors": get_field("ì €ì"),
        "publisher": get_field("ë°œí–‰ê¸°ê´€"),
        "journal": get_field("í•™ìˆ ì§€ëª…"),
        "issue": get_field("ê¶Œí˜¸ì‚¬í•­"),
        "year": get_field("ë°œí–‰ì—°ë„")
    }

def main():
    # ===== ê¸°ì¡´ CSV ë¶ˆëŸ¬ì˜¤ê¸° =====
    done_links = set()
    try:
        df = pd.read_csv(OUT_FILE)
        done_links = set(df["link"].dropna())
        print(f"ì´ë¯¸ ìˆ˜ì§‘ëœ ë…¼ë¬¸ {len(done_links)}ê±´ â†’ ì¤‘ë³µ ìŠ¤í‚µ ì˜ˆì •")
    except FileNotFoundError:
        print("ê¸°ì¡´ CSV ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„± ì‹œì‘")

    driver.get(START_URL)
    human_delay()

    current_block_start = START_PAGE
    csv_fields = ["database", "keyword", "title", "authors", "publisher", "journal", "issue", "year", "link"]

    with open(OUT_FILE, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=csv_fields)
        if f.tell() == 0:
            writer.writeheader()  # ìƒˆ íŒŒì¼ì´ë©´ í—¤ë” ì¶”ê°€

        while current_block_start <= END_PAGE:
            block_end = min(current_block_start + 9, END_PAGE)

            for page_num in range(current_block_start, block_end + 1):
                print(f"\n=== ğŸ“„ í˜ì´ì§€ {page_num} ===")
                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".srchResultListW > ul > li")))

                items = driver.find_elements(By.CSS_SELECTOR, ".srchResultListW > ul > li > div.cont.ml60 > p.title > a")
                for i, a in enumerate(items, start=1):
                    title, href = a.text.strip(), a.get_attribute("href")

                    if href in done_links:
                        print(f"[SKIP] ì´ë¯¸ ìˆ˜ì§‘ë¨: {title}")
                        continue

                    print(f"[{page_num}-{i}] {title}")

                    driver.execute_script("window.open(arguments[0]);", href)
                    driver.switch_to.window(driver.window_handles[-1])

                    fields = extract_detail_fields()
                    fields.update({
                        "title": title,
                        "link": href,
                        "database": "RISS",
                        "keyword": SEARCH_KEYWORD
                    })

                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])

                    writer.writerow(fields)   # í•œ ê±´ì”© CSV append ì €ì¥
                    done_links.add(href)

                    human_delay()

                # í˜ì´ì§€ ì´ë™
                if page_num < block_end:
                    nth = (page_num - current_block_start) + 4
                    selector = f"#divContent > div > div.rightContent.wd756 > div > div.paging > a:nth-child({nth})"
                    driver.find_element(By.CSS_SELECTOR, selector).click()
                    human_delay()

            # ë¸”ë¡ ë â†’ next ë²„íŠ¼ ëˆŒëŸ¬ì„œ ë‹¤ìŒ ë¸”ë¡ ì´ë™
            if block_end < END_PAGE:
                next_btn = driver.find_element(By.CSS_SELECTOR, "#divContent > div > div.rightContent.wd756 > div > div.paging > a.next1")
                next_btn.click()
                human_delay()

            current_block_start += 10

    driver.quit()
    print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ (ì´ {len(done_links)}ê±´ ì €ì¥ë¨)")

if __name__ == "__main__":
    main()